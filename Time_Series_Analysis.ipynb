{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cb55eea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8d4c505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanAbsolutePercentageError as MAPE\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c8615fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreate_stock_data(stock_name,period):\n",
    "    company = yf.Ticker(stock_name)\n",
    "    df = company.history(period=period)\n",
    "    \n",
    "    #Sepreate the dates of the stock for further use if required\n",
    "    date = (df.reset_index())['Date']\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Remove data object from the database\n",
    "    df = (df.reset_index()).drop('Date',axis=1)\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create the current trend of the current stock\n",
    "    t = []\n",
    "    for i in range(len(df)):\n",
    "        if(df['Open'].iloc[i]-df['Close'].iloc[i]>0):\n",
    "            t.append(\"DOWN\")\n",
    "        else:\n",
    "            t.append(\"UP\")\n",
    "            \n",
    "    df['Trend']=t\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create the trend history of the stock\n",
    "    th=[0]\n",
    "    current_trend = df['Trend'].iloc[0]\n",
    "    count = 0\n",
    "    for i in range(1,len(df)):\n",
    "        if(current_trend==df['Trend'].iloc[i]):\n",
    "            count+=1\n",
    "            th.append(count)\n",
    "        else:\n",
    "            count = 0\n",
    "            th.append(count)\n",
    "            current_trend = df['Trend'].iloc[i]\n",
    "            \n",
    "    df[\"Trend history\"]=th\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create the comparison to the change since last peak\n",
    "    p=[]\n",
    "    v=[]\n",
    "    if(df['Trend'].iloc[0]==\"DOWN\"):\n",
    "        peak = df['Open'].iloc[0]\n",
    "        valley = df['Close'].iloc[0]\n",
    "    else:\n",
    "        valley = df['Open'].iloc[0]\n",
    "        peak = df['Close'].iloc[0]\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "\n",
    "        p.append(peak-df['Close'].iloc[i])\n",
    "        v.append(valley-df['Close'].iloc[i])\n",
    "\n",
    "        if peak<df['Close'].iloc[i]:\n",
    "            peak = df['Close'].iloc[i]\n",
    "        if valley>df['Close'].iloc[i]:\n",
    "            valley = df['Close'].iloc[i]\n",
    "            \n",
    "    df['Change since last peak']=p\n",
    "    df['Change since last drop']=v\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create the local change of daily stock\n",
    "    c=[]\n",
    "    cm=[]\n",
    "    for i in range(0,len(df)):\n",
    "        c.append(df['Open'].iloc[i]-df['Close'].iloc[i])\n",
    "        cm.append(df['High'].iloc[i]-df['Low'].iloc[i])\n",
    "\n",
    "    df['Local Change']=c\n",
    "    df['Local range of stock price']=cm\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create dummy variable for the categorical variable\n",
    "    df = pd.get_dummies(df,drop_first=True)\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Create the label for the change from tommorow, the data that needs to be predicted\n",
    "    next_day_change = df[1:]\n",
    "    next_day_change = next_day_change['Local Change']\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Remove The last column as the it is redundant\n",
    "    df.drop(index=df.index[-1],axis=0,inplace=True)\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #Break the data into features and labels\n",
    "    X = df\n",
    "    y = next_day_change\n",
    "    #-------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return(date,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c87696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions(X_test,y_test,model,path):\n",
    "    test_predictions = model.predict(X_test).flatten()\n",
    "    #test_results = pd.DataFrame(data={'test Predictions':test_predictions, 'Actuals':y_test})\n",
    "    error = mean_absolute_percentage_error(y_test, test_predictions)\n",
    "    \n",
    "    fig, axe = plt.subplots(figsize=(7, 3.5), dpi=800)\n",
    "    axe.plot(test_predictions)\n",
    "    axe.plot(y_test)\n",
    "    axe.legend(['Test','Actual'])\n",
    "    axe.text(0,1.05,error,transform=axe.transAxes)\n",
    "    \n",
    "    fig.savefig(path+'/test_figure.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "591e5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(df, window_size=5):\n",
    "  df_as_np = df\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [[a] for a in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "23ac1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y_2D(df, window_size=5):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][0]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cca98b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_conv(X,y,window = 5,path = ''):\n",
    "    X_train, y_train = X[:int(len(X)*0.7)],y[:int(len(X)*0.7)]\n",
    "    X_val, y_val = X[int(len(X)*0.7):int(len(X)*0.85)],y[int(len(X)*0.7):int(len(X)*0.85)]\n",
    "    X_test, y_test = X[int(len(X)*0.85):],y[int(len(X)*0.85):]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((window, 1)))\n",
    "    model.add(Conv1D(4096,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, 'relu'))\n",
    "    model.add(Dense(8, 'relu'))\n",
    "    model.add(Dense(1, 'linear'))\n",
    "\n",
    "    cp1 = ModelCheckpoint(path, save_best_only=True)\n",
    "    model.compile(loss=MAPE(), optimizer=Adam(learning_rate=0.001), metrics=[MeanAbsolutePercentageError()])\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50,callbacks=[cp1])\n",
    "\n",
    "    model = load_model(path+'/')\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "83481b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_LSTM_2D(X,y,window = 5,path = ''):\n",
    "    X_train, y_train = X[:int(len(X)*0.7)],y[:int(len(X)*0.7)]\n",
    "    X_val, y_val = X[int(len(X)*0.7):int(len(X)*0.85)],y[int(len(X)*0.7):int(len(X)*0.85)]\n",
    "    X_test, y_test = X[int(len(X)*0.85):],y[int(len(X)*0.85):]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = np.array(scaler.fit_transform(X_train))\n",
    "    X_test = np.array(scaler.transform(X_test))\n",
    "    X_val = np.array(scaler.transform(X_val))\n",
    "    \n",
    "    print(X_train.shape,y_train.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((window, X.shape[2])))\n",
    "    model.add(Conv1D(4096,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, 'relu'))\n",
    "    model.add(Dense(8, 'relu'))\n",
    "    model.add(Dense(1, 'linear'))\n",
    "\n",
    "    cp1 = ModelCheckpoint('model/'+path, save_best_only=True)\n",
    "    model.compile(loss=MAPE(), optimizer=Adam(learning_rate=0.0001), metrics=[MeanAbsolutePercentageError()])\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, callbacks=[cp1])\n",
    "\n",
    "    model = load_model(path+'/')\n",
    "    \n",
    "    plt.plot(model.predict(X_train).flatten()[-100:])\n",
    "    plt.plot(y_train[-100:])\n",
    "    plt.legend(['train','Actual'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "be3dfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(stock):\n",
    "    date,X,y = genreate_stock_data(stock,'max')\n",
    "    X_open,y_open = df_to_X_y(X['Open'],window_size=5)\n",
    "    X_close,y_close = df_to_X_y(X['Close'],window_size=5)\n",
    "    \n",
    "    path_create ='models/'+stock+'/time_series'\n",
    "    model_open  = create_model_conv(X_open,y_open,path=path_create+'/open',window=5)\n",
    "    model_close  = create_model_conv(X_open,y_open,path=path_create+'/close',window=5)\n",
    "    \n",
    "    test_predictions(X_open[int(len(X_open)*0.85):],y_open[int(len(y_open)*0.85):],model_open,path_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "630b6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(stock):\n",
    "    path_exist ='models/'+stock+'/time_series'\n",
    "    \n",
    "    model_open = load_model(path_exist+'/open')\n",
    "    model_close = load_model(path_exist+'/close')\n",
    "    \n",
    "    date,X,y = genreate_stock_data(stock,'1mo')\n",
    "    \n",
    "    closed = X['Close'][-5:]\n",
    "    opened = X['Open'][-5:]\n",
    "    \n",
    "    for i in range(5):\n",
    "        y_open = model_open.predict([np.array([opened[-5:]])])\n",
    "        opened = np.append(opened,y_open.flatten()[0])\n",
    "        y_close = model_close.predict([np.array([closed[-5:]])])\n",
    "        closed = np.append(closed,y_close.flatten()[0])\n",
    "        \n",
    "    fig, axe = plt.subplots(figsize=(7, 3.5), dpi=800)\n",
    "    axe.plot(closed)\n",
    "    axe.plot(opened,linestyle=':')\n",
    "    axe.legend(['Close','Open'])\n",
    "    fig.savefig(path_exist+'/projected.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b247486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
